---
title: "Importation des données"
title-block-banner: true
description: | 
  Fonction qui permet le téléchargement des bases de données.
# à changer
date: "2022-12-20"
# Modifier les détails que vous voulez
author:
  - name: "Rémi Turcot-Roy"
    # Votre site web perso ou github
    url: https://github.com/rTurcotroy
    # les champs d'affiliation sont optionnels, vous pouvez les
    # comment out en ajoutant un # devant.
    affiliation: FAS1002
    affiliation-url: https://FAS1002.github.io/A22
    # changer pour votre propre orcid id
    # https://orcid.org/ pour vous inscrire.
    orcid: 0000-0000-0000-0000

# TRUE == Générer une citation pour cette page précise. Pour enlever, mettre false.
citation: true
# Inclure les références que vous utilisez dans vos rapports. Je conseille Zotero pour construire
# ce fichier ou de connecter RStudio directement pour pouvoir citer avec @nom-de-reference.
bibliography: references.bib
---

# Les données

Pour commencer, il est important de télécharger les données que nous utiliserons pour ce travail. Ceux-ci proviennent de deux sources différentes et nous avions certaines conditions à respecter. Nous devions télécharger les données avec un certain cycle. Pour faire cela, nous avons créé une fonction qui demande la récurrence des téléchargements, le nom que l'on veut donner au document et l'URL du document. Pour les données provenant de Our World in Data^1^ , il a été simple de les télécharger via la fonction. Ce qui n'a pas été le cas avec la seconde base de données Gapminder^2^ qui sont sous format ,xlsx, mais surtout qui n'a visiblement pas d'URL de téléchargement fonctionnel sans l'implication humaine.

Ainsi, la suite du travail consiste en l'exploration des données et de l'analyse de ceux-ci

```{r echo=FALSE, warning=FALSE, message=FALSE}
library(fs)
library(lubridate)
library(tidyverse)
library(skimr)

```

```{r download, cache=TRUE}
list.files("data/raw")
bas_path <- path("data", "raw")

telechargement <-function(recurence, nom, url){
    x =0 
    trouve = 0
    if (recurence == "jour") {
        aujourd <- paste(today(), nom, sep = "_") 
        dateChoisi <- today()
        print(aujourd)
        
    } else if (recurence == "mois") {
        aujourd <- paste(month(today()), nom, sep = "_")
        dateChoisi <- month(today())
        print(aujourd)
        
    }
    
    
    while (x <= length(list.files("data/raw"))) {
        x = x +1
        
        
        if (x > 0 & x <= length(list.files("data/raw"))) {
            if (aujourd == list.files("data/raw")[x]) {
                trouve = 1
                print("trouve")
            }
        }
       
        

    }
    if (trouve == 0 ) {
        URL <- url


        fname <- paste(dateChoisi, nom, sep = "_")

        fpath <- path(bas_path, fname)

        download.file(url = URL, 
                          destfile = fpath)
        trouve = 1
            
    }
    return("succes")
}

telechargement("jour", "Co2_data.csv", "https://nyc3.digitaloceanspaces.com/owid-public/data/co2/owid-co2-data.csv")

telechargement("mois", "energy_data.csv", "https://nyc3.digitaloceanspaces.com/owid-public/data/energy/owid-energy-data.csv")

#telechargement("mois", "expectancy_data.xlsx", "https://raw.githubusercontent.com/Gapminder-Indicators/lex/master/lex-by-gapminder.xlsx")



list.files("data/raw")
```

```{r read}
Co2_name <- paste(today(), "Co2_data.csv", sep = "_") 
energy_name <- paste(month(today()), "energy_data.csv", sep = "_") 
expectancy_name <- paste(month(today()), "expectancy_data.xlsx", sep = "_") 

Co2_data <-  read.csv(file = path(bas_path, Co2_name))
Energy_data <- read.csv(file = path(bas_path, energy_name))
#expectancy_data <- read_excel("data/raw/12_expectancy_data.xlsx", 
#sheet = "countries_and_territories")

 
 
```

Les données proviennent entre autres de:

@owidenergy

@gaplife

@owidco2
